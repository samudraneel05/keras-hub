# TODO: Add Qwen2-VL presets once PR is accepted
# Right now it is filled with dummy values

"""Qwen2-VL preset configurations."""

backbone_presets = {}

# backbone_presets = {
#     "qwen2_vl_2b_base": {
#         "metadata": {
#             "description": (
#                 "2 billion parameter Qwen2-VL vision-language base model. "
#                 "Pretrained model without instruction tuning. Supports image "
#                 "and video understanding with multimodal "
#                 "rotary position embeddings."
#             ),
#             "params": 2014341120,
#             "path": "qwen2_vl",
#         },
#         "kaggle_handle": "kaggle://keras/qwen2_vl/keras/qwen2_vl_2b_base/1",
#     },
#     "qwen2_vl_2b_instruct": {
#         "metadata": {
#             "description": (
#                 "2 billion parameter Qwen2-VL vision-language model. "
#                 "Instruction-tuned for image and video understanding with "
#                 "multimodal rotary position embeddings."
#             ),
#             "params": 2014341120,
#             "path": "qwen2_vl",
#         },
#         "kaggle_handle": "kaggle://keras/qwen2_vl/keras/qwen2_vl_2b_instruct/1",
#     },
#     "qwen2_vl_7b_base": {
#         "metadata": {
#             "description": (
#                 "7 billion parameter Qwen2-VL vision-language base model. "
#                 "Pretrained model without instruction tuning. Supports image "
#                 "and video understanding with multimodal "
#                 "rotary position embeddings."
#             ),
#             "params": 7616192512,
#             "path": "qwen2_vl",
#         },
#         "kaggle_handle": "kaggle://keras/qwen2_vl/keras/qwen2_vl_7b_base/1",
#     },
#     "qwen2_vl_7b_instruct": {
#         "metadata": {
#             "description": (
#                 "7 billion parameter Qwen2-VL vision-language model. "
#                 "Instruction-tuned for image and video understanding with "
#                 "multimodal rotary position embeddings."
#             ),
#             "params": 7616192512,
#             "path": "qwen2_vl",
#         },
#         "kaggle_handle": "kaggle://keras/qwen2_vl/keras/qwen2_vl_7b_instruct/1",
#     },
#     "qwen2_vl_72b_base": {
#         "metadata": {
#             "description": (
#                 "72 billion parameter Qwen2-VL vision-language base model. "
#                 "Pretrained model without instruction tuning. Supports image "
#                 "and video understanding with multimodal "
#                 "rotary position embeddings."
#             ),
#             "params": 72706203648,
#             "path": "qwen2_vl",
#         },
#         "kaggle_handle": "kaggle://keras/qwen2_vl/keras/qwen2_vl_72b_base/1",
#     },
#     "qwen2_vl_72b_instruct": {
#         "metadata": {
#             "description": (
#                 "72 billion parameter Qwen2-VL vision-language model. "
#                 "Instruction-tuned for image and video understanding with "
#                 "multimodal rotary position embeddings."
#             ),
#             "params": 72706203648,
#             "path": "qwen2_vl",
#         },
#         "kaggle_handle": "kaggle://keras/qwen2_vl/keras/qwen2_vl_72b_instruct/1",
#     },
# }
